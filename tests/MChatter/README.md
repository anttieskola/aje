Just a dummy app to chat with AI models running locally with llama.cpp

# Done
- test out simple instructions
- test streaming

# Todo ideas
- test creating history
- test context size
- how to figure out context size limits
- when context size exceeds limits learn to use tokenization can we reduce required context size